{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\Abbas Mrb\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Abbas Mrb/AppData/Local/Programs/Python/Python39/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "def digitize_catg_feature(col_index, df):\n",
    "    ladels = pd.factorize(df.iloc[:, col_index].unique(), na_sentinel=None)\n",
    "    ladels_replacement = {}\n",
    "    for i in range(len(ladels[0])): ladels_replacement[ladels[1][i]] = ladels[0][i]\n",
    "    df.iloc[:, col_index] = df.iloc[:, col_index].replace(ladels_replacement)\n",
    "    return df\n",
    "\n",
    "# Wdbc\n",
    "# data = pd.read_csv(f'datasets/DS01.data', header=None)\n",
    "# data = data.replace('?', np.nan)\n",
    "# data = digitize_catg_feature(1, data)\n",
    "# data = data.dropna()\n",
    "# data.insert(len(data.columns)-1, 'LABEL', data.pop(1))\n",
    "# data.to_csv('datasets/DS01.csv', index=False)\n",
    "\n",
    "# Lung canser\n",
    "# data = pd.read_csv(f'datasets/DS02.data', header=None)\n",
    "# data = data.replace('?', np.nan)\n",
    "# data = data.dropna()\n",
    "# data.insert(len(data.columns)-1, 'LABEL', data.pop(0))\n",
    "# data.to_csv('datasets/DS02.csv', index=False)\n",
    "\n",
    "# data = pd.read_csv(f'datasets/DS03.data', header=None)\n",
    "# data = data.replace('?', np.nan)\n",
    "# data = digitize_catg_feature(-1, data)\n",
    "# data = data.dropna()\n",
    "# data.insert(len(data.columns)-1, 'LABEL', data.pop(data.columns[-1]))\n",
    "# data.to_csv('datasets/DS03.csv', index=False)\n",
    "\n",
    "\n",
    "# digits = load_digits()\n",
    "# data = pd.DataFrame(data=pd.DataFrame(data=digits['data']))\n",
    "# data.insert(len(data.columns), 'LABEL', digits['target'])\n",
    "# data = data.sample(n=1000)\n",
    "# data.to_csv('datasets/DS04.csv', index=False)\n",
    "\n",
    "# data = pd.read_csv(f'datasets/raw/MADELON/madelon_train.data', delimiter=r\"\\s+\", header=None)\n",
    "# y = pd.read_csv(f'datasets/raw/MADELON/madelon_train.labels', header=None)\n",
    "# data['LABEL'] = y[0]\n",
    "# data = data.sample(n=600)\n",
    "# data.to_csv('datasets/DS05.csv', index=False)\n",
    "\n",
    "# data = pd.read_csv(f'datasets/DS06.data')\n",
    "# data.drop(columns=data.columns[-5:], axis=1, inplace=True)\n",
    "# data.drop(columns=[\"FLOOR\"], inplace=True)\n",
    "# data.insert(len(data.columns)-1, 'LABEL', data.pop(data.columns[-1]))\n",
    "# data = data.sample(n=900)\n",
    "# data.to_csv('datasets/DS06.csv', index=False)\n",
    "\n",
    "# data = pd.read_csv(f'datasets/X_train.txt', delimiter=r\"\\s+\", header=None)\n",
    "# y = pd.read_csv(f'datasets/y_train.txt', header=None)\n",
    "# data['LABEL'] = y[0]\n",
    "# data = data.sample(n=900)\n",
    "# data.to_csv('datasets/DS07.csv', index=False)\n",
    "\n",
    "# data = pd.read_csv(f'datasets/final_X_train.txt', delimiter=\",\", header=None)\n",
    "# y = pd.read_csv(f'datasets/final_y_train.txt', header=None)\n",
    "# data['LABEL'] = y[0]\n",
    "# data = data.sample(n=900)\n",
    "# data.to_csv('datasets/DS07-2.csv', index=False)\n",
    "\n",
    "# HAPT\n",
    "# data = pd.read_csv(f'datasets/raw/HAPT/X_train.txt', delimiter=r\"\\s+\", header=None)\n",
    "# y = pd.read_csv(f'datasets/raw/HAPT/y_train.txt', header=None)\n",
    "# data['LABEL'] = y[0]\n",
    "# data = data.sample(n=1200)\n",
    "# data.to_csv('datasets/DS08.csv', index=False)\n",
    "\n",
    "# isolet5\n",
    "# data = pd.read_csv(f'datasets/isolet5.data', header=None)\n",
    "# data.insert(len(data.columns)-1, 'LABEL', data.pop(data.columns[-1]))\n",
    "# data = data.sample(n=1040)\n",
    "# data.to_csv('datasets/DS09.csv', index=False)\n",
    "\n",
    "\n",
    "# fac = pd.read_csv(f'datasets/raw/mfeat/mfeat-fac', delimiter=r\"\\s+\", header=None)\n",
    "# fou = pd.read_csv(f'datasets/raw/mfeat/mfeat-fou', delimiter=r\"\\s+\", header=None)\n",
    "# kar = pd.read_csv(f'datasets/raw/mfeat/mfeat-kar', delimiter=r\"\\s+\", header=None)\n",
    "# mor = pd.read_csv(f'datasets/raw/mfeat/mfeat-mor', delimiter=r\"\\s+\", header=None)\n",
    "# pix = pd.read_csv(f'datasets/raw/mfeat/mfeat-pix', delimiter=r\"\\s+\", header=None)\n",
    "# zer = pd.read_csv(f'datasets/raw/mfeat/mfeat-zer', delimiter=r\"\\s+\", header=None)\n",
    "# data = pd.concat([fac, fou, kar, mor, pix, zer], axis=1)\n",
    "# data['LABEL']=np.divmod(np.arange(len(data)), 200)[0]\n",
    "# data = data.sample(n=1000)\n",
    "# data.to_csv('datasets/DS10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\Abbas Mrb\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Abbas Mrb/AppData/Local/Programs/Python/Python39/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class MOBGA_AOS:\n",
    "    def __init__(self, LP = 5, max_nFE = 500, pop_size = 100, p_c = 0.9):\n",
    "        self.max_nFE = max_nFE\n",
    "        self.pop_size = pop_size\n",
    "        self.operator_pool = ['single-point', 'two-point', 'uniform', 'shuffle', 'reduced-surrogate']\n",
    "        self.LP = LP\n",
    "        self.p_c = p_c\n",
    "\n",
    "        # Q = pool_size\n",
    "        self.Q = len(self.operator_pool)\n",
    "        self.OSP = [1/self.Q for _ in range(self.Q)]\n",
    "\n",
    "    def load_data(self, dataset_name):\n",
    "        data = pd.read_csv(f'datasets/{dataset_name}').to_numpy()\n",
    "        self.X = data[:, :-1]\n",
    "        self.y = data[:, -1]\n",
    "        self.d = self.X.shape[1]\n",
    "        self.p_m = 1/self.d\n",
    "        # self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "    def init_pop(self):\n",
    "        if(self.d > 250):\n",
    "            pop = []\n",
    "            for _ in range(self.pop_size):\n",
    "                individual = np.zeros(self.d)\n",
    "                individual[:100] = 1\n",
    "                np.random.shuffle(individual)\n",
    "                pop.append(individual)\n",
    "        else:\n",
    "            return [np.random.choice([0, 1], size=self.d) for _ in range(self.pop_size)]\n",
    "    \n",
    "    def one_point_crossover(self, p1, p2):\n",
    "        cross_point = np.random.randint(0, self.d)\n",
    "        c1 = list(p1[:cross_point]) + list(p2[cross_point:])\n",
    "        c2 = list(p2[:cross_point]) + list(p1[cross_point:])\n",
    "        return [c1, c2]\n",
    "    \n",
    "    def two_point_crossover(self, p1, p2):\n",
    "        cross_points = np.random.randint(0, self.d, 2)\n",
    "        cross_points = np.sort(cross_points)\n",
    "        c1 = list(p1[:cross_points[0]]) + list(p2[cross_points[0]:cross_points[1]]) + list(p1[cross_points[1]:])\n",
    "        c2 = list(p2[:cross_points[0]]) + list(p1[cross_points[0]:cross_points[1]]) + list(p2[cross_points[1]:])\n",
    "        return [c1, c2]\n",
    "\n",
    "    def uniform_crossover(self, p1, p2):\n",
    "        c1 = np.full(self.d, None).tolist()\n",
    "        c2 = np.full(self.d, None).tolist()\n",
    "        for i in range(self.d):\n",
    "            rand_rate = np.random.uniform(0, 1)\n",
    "            if(rand_rate >= 0.5):\n",
    "                c1[i] = p1[i]\n",
    "                c2[i] = p2[i]\n",
    "            else:\n",
    "                c1[i] = p2[i]\n",
    "                c2[i] = p1[i]\n",
    "        return [c1, c2]\n",
    "    \n",
    "    def shuffle_crossover(self, p1, p2):\n",
    "        c1, c2 = p1, p2\n",
    "        index = np.random.choice(np.arange(0, self.d), self.d, replace = False)\n",
    "        ran = np.random.randint(0, self.d)\n",
    "        for i in range(ran):\n",
    "            ind = index[i]\n",
    "            c1[ind] = p2[ind]\n",
    "            c2[ind] = p1[ind]\n",
    "        return [c1, c2]\n",
    "    \n",
    "    # def shuffle_crossover(self, p1, p2):\n",
    "    #     p1 = shuffle(p1)\n",
    "    #     p2 = shuffle(p2)\n",
    "    #     offsrping = self.one_point_crossover(p1, p2)\n",
    "    #     return offsrping\n",
    "\n",
    "    def reduced_surrogate_crossover(self, p1, p2):\n",
    "        if(len(np.array(np.where(np.array(p1) != np.array(p2))).flatten()) > 0):\n",
    "            cross_point = np.random.choice(np.array(np.where(np.array(p1) != np.array(p2))).flatten())\n",
    "            c1 = list(p1[:cross_point]) + list(p2[cross_point:])\n",
    "            c2 = list(p2[:cross_point]) + list(p1[cross_point:])\n",
    "            return [c1, c2]\n",
    "        else:\n",
    "            return [p1, p2]\n",
    "    \n",
    "    def crossover(self, parents, operator_idx):\n",
    "        p = np.random.uniform(0, 1)\n",
    "        if p > self.p_c:\n",
    "            return parents\n",
    "        \n",
    "        op_name = self.operator_pool[operator_idx]\n",
    "        if(op_name == \"single-point\"):\n",
    "            offspring = self.one_point_crossover(parents[0], parents[1])\n",
    "        elif(op_name == \"two-point\"):\n",
    "            offspring = self.two_point_crossover(parents[0], parents[1])\n",
    "        elif(op_name == \"uniform\"):\n",
    "            offspring = self.uniform_crossover(parents[0], parents[1])\n",
    "        elif(op_name == \"shuffle\"):\n",
    "            offspring = self.shuffle_crossover(parents[0], parents[1])\n",
    "        elif(op_name == \"reduced-surrogate\"):\n",
    "            offspring = self.reduced_surrogate_crossover(parents[0], parents[1])\n",
    "        else:\n",
    "            raise Exception(\"Unknown crossover operator!\")\n",
    "        \n",
    "        for i, child in enumerate(offspring):\n",
    "            if(not np.any(child)): \n",
    "                print(op_name)\n",
    "                print(\"XOVER\")\n",
    "                print(f\"C: {offspring[i]}\")\n",
    "                offspring[i] = parents[i]\n",
    "                print(f\"P: {parents[i]}\")\n",
    "        \n",
    "        return offspring\n",
    "    \n",
    "    def mutation(self, individual):\n",
    "        # Select a fraction of individual\n",
    "        frac_idxs = np.random.choice(range(self.d), int(0.5 * self.d))\n",
    "        indiv = individual.copy()\n",
    "        for idx in frac_idxs:\n",
    "            p = np.random.uniform(0, 1)\n",
    "            if p < self.p_m:\n",
    "                new_gene = np.random.randint(0, 2)\n",
    "                # indiv[idx] = new_gene\n",
    "                indiv[idx] = 0 if (indiv[idx] == 1) else 1\n",
    "        if(not np.any(indiv)): \n",
    "            print(\"MUTE\")\n",
    "            print(f\"C: {individual}\")\n",
    "            print(f\"P: {indiv}\")\n",
    "            idx = np.random.randint(0, self.d)\n",
    "            individual[idx] = 1\n",
    "            return individual\n",
    "        else:\n",
    "            return indiv\n",
    "\n",
    "    def score_individual_1(self, individual):\n",
    "        model = KNeighborsClassifier(n_neighbors=3)\n",
    "        indexes = np.array(np.where(np.array(individual) == 1)).flatten()\n",
    "        X = (self.X[:, indexes]).reshape(len(self.X), len(indexes))\n",
    "        ss = ShuffleSplit(n_splits=3, test_size=0.3, random_state=10)\n",
    "        Nerr_Nall = []\n",
    "        for train_index, test_index in ss.split(X):\n",
    "            model.fit(X[train_index], self.y[train_index])\n",
    "            y_pred = model.predict(X[test_index])\n",
    "            y_test = self.y[test_index]\n",
    "            # misclassified = np.where(y_test != y_pred)\n",
    "            Nerr_Nall.append((np.sum(y_pred != y_test))/len(y_test))\n",
    "        return np.round(np.mean(Nerr_Nall) * 100, 2)\n",
    "\n",
    "    def score_individual_2(self, individual):\n",
    "        return np.sum(individual)\n",
    "\n",
    "    def fast_non_dominated_sort(self, values1, values2):\n",
    "        S = [[] for i in range(0,len(values1))]\n",
    "        front = [[]]\n",
    "        n = [0 for i in range(0,len(values1))]\n",
    "        rank = [0 for i in range(0, len(values1))]\n",
    "\n",
    "        for p in range(0, len(values1)):\n",
    "            S[p] = []\n",
    "            n[p] = 0\n",
    "            for q in range(0, len(values1)):\n",
    "                if (values1[p] < values1[q] and values2[p] < values2[q]) \\\n",
    "                    or (values1[p] <= values1[q] and values2[p] < values2[q]) \\\n",
    "                    or (values1[p] < values1[q] and values2[p] <= values2[q]):\n",
    "                    if q not in S[p]:\n",
    "                        S[p].append(q)\n",
    "                elif (values1[q] < values1[p] and values2[q] < values2[p]) \\\n",
    "                    or (values1[q] <= values1[p] and values2[q] < values2[p]) \\\n",
    "                    or (values1[q] < values1[p] and values2[q] <= values2[p]):\n",
    "                    n[p] = n[p] + 1\n",
    "            if n[p] == 0:\n",
    "                rank[p] = 0\n",
    "                if p not in front[0]:\n",
    "                    front[0].append(p)\n",
    "\n",
    "        i = 0\n",
    "        while(front[i] != []):\n",
    "            Q = []\n",
    "            for p in front[i]:\n",
    "                for q in S[p]:\n",
    "                    n[q] = n[q] - 1\n",
    "                    if(n[q] == 0):\n",
    "                        rank[q] = i+1\n",
    "                        if q not in Q:\n",
    "                            Q.append(q)\n",
    "            i = i+1\n",
    "            front.append(Q)\n",
    "\n",
    "        del front[len(front)-1]\n",
    "        return front\n",
    "    \n",
    "    def index_locator(self, a, list):\n",
    "        for i in range(0, len(list)):\n",
    "            if list[i] == a:\n",
    "                return i\n",
    "        return -1\n",
    "\n",
    "    def sort_by_values(self, list1, values):\n",
    "        sorted_list = []\n",
    "        while(len(sorted_list)!=len(list1)):\n",
    "            if self.index_locator(min(values),values) in list1:\n",
    "                sorted_list.append(self.index_locator(min(values),values))\n",
    "            values[self.index_locator(min(values),values)] = math.inf\n",
    "        return sorted_list\n",
    "\n",
    "    def crowding_distance(self, values1, values2, front):\n",
    "        distance = [0 for i in range(0,len(front))]\n",
    "        sorted1 = self.sort_by_values(front, values1[:])\n",
    "        sorted2 = self.sort_by_values(front, values2[:])\n",
    "        distance[0] = 9999999999999999\n",
    "        distance[len(front) - 1] = 9999999999999999\n",
    "        for k in range(1,len(front)-1):\n",
    "            distance[k] = distance[k] + (values1[sorted1[k+1]] - values2[sorted1[k-1]])/(max(values1)-min(values1))\n",
    "        for k in range(1,len(front)-1):\n",
    "            distance[k] = distance[k] + (values1[sorted2[k+1]] - values2[sorted2[k-1]])/(max(values2)-min(values2))\n",
    "        return distance\n",
    "        \n",
    "    def update_OSP(self, RD, PN):\n",
    "        S_q_1 = RD.sum(axis=0)\n",
    "        S_q_2 = PN.sum(axis=0)\n",
    "\n",
    "        S_q_3 = S_q_2\n",
    "        S_q_3[S_q_3 == 0] = 0.0001\n",
    "\n",
    "        S_q_4 = S_q_1/(S_q_2 + S_q_3)\n",
    "        self.OSP = S_q_4/np.sum(S_q_4)\n",
    "        if(np.isnan(self.OSP).all()): \n",
    "            print(\"OSP FUCKED\")\n",
    "            self.OSP = [1/self.Q for _ in range(self.Q)]\n",
    "\n",
    "    # def dominance_comparison(self, individuals):\n",
    "    #     objective1_values = [self.score_individual_1(individual) for individual in individuals]\n",
    "    #     objective2_values = [self.score_individual_2(individual) for individual in individuals]\n",
    "    #     return self.fast_non_dominated_sort(objective1_values, objective2_values)\n",
    "\n",
    "    # def credit_assigment(self, parents, offspring, op_idx):\n",
    "    #     paretos = self.dominance_comparison(offspring)\n",
    "\n",
    "    #     if(len(paretos[0]) == 1):\n",
    "    #         for i in range(2):\n",
    "    #             individuals = [parents[paretos[0][0]], offspring[i]]\n",
    "    #             comparisions = self.dominance_comparison(individuals)\n",
    "    #             if(len(comparisions[0]) == 1 and comparisions[0][0] == 1):\n",
    "    #                 self.n_penalty[op_idx] += 1\n",
    "    #             else:\n",
    "    #                 self.n_reward[op_idx] += 1\n",
    "    #     else:\n",
    "    #         for i in range(2):\n",
    "    #             comparision_individuals = [parents[paretos[0][0]], offspring[i]]\n",
    "    #             comparisions1 = self.dominance_comparison(comparision_individuals)\n",
    "    #             comparision_individuals = [parents[paretos[0][1]], offspring[i]]\n",
    "    #             comparisions2 = self.dominance_comparison(comparision_individuals)\n",
    "    #             if((len(comparisions1[0]) != 1) and (len(comparisions2[0]) != 1)\\\n",
    "    #                or (((len(comparisions1[0]) == 1) and comparisions1[0][0] != 1)\\\n",
    "    #                 and ((len(comparisions2[0]) == 1) and comparisions2[0][0] != 1))):\n",
    "    #                 self.n_reward[op_idx] += 1\n",
    "    #             else:\n",
    "    #                 self.n_penalty[op_idx] += 1\n",
    "\n",
    "    # def dominance_comparison(self, individuals):\n",
    "    #     objective1_values = [self.score_individual_1(individual) for individual in individuals]\n",
    "    #     objective2_values = [self.score_individual_2(individual) for individual in individuals]\n",
    "    #     and_condition = True\n",
    "    #     or_condition = False\n",
    "    #     for first, second in zip(objective1_values, objective2_values):\n",
    "    #         and_condition = and_condition and first <= second\n",
    "    #         or_condition = or_condition or first < second\n",
    "    #     return (and_condition and or_condition)\n",
    "\n",
    "    # def dominance_comparison(self, individuals):\n",
    "    #     objective1_values = [self.score_individual_1(individual) for individual in individuals]\n",
    "    #     objective2_values = [self.score_individual_2(individual) for individual in individuals]\n",
    "    #     return ((objective1_values[0] < objective1_values[1]) and (objective2_values[0] < objective2_values[1]))\n",
    "\n",
    "    def dominance_comparison(self, individuals):\n",
    "        objective1_values = [self.score_individual_1(individual) for individual in individuals]\n",
    "        objective2_values = [self.score_individual_2(individual) for individual in individuals]\n",
    "        and_cond = ((objective1_values[0] <= objective1_values[1]) and (objective2_values[0] <= objective2_values[1]))\n",
    "        or_cond = ((objective1_values[0] < objective1_values[1]) or (objective2_values[0] < objective2_values[1]))\n",
    "        return (and_cond and or_cond)\n",
    "\n",
    "    def credit_assigment(self, parents, offspring, op_idx):\n",
    "        p1_vs_p2 = self.dominance_comparison(parents)\n",
    "        p2_vs_p1 = self.dominance_comparison([parents[1], parents[0]])\n",
    "\n",
    "        if(p1_vs_p2 or p2_vs_p1):\n",
    "            if(p1_vs_p2): \n",
    "                non_dominated_parent = parents[0]\n",
    "            else: \n",
    "                non_dominated_parent = parents[1]\n",
    "            for i in range(2):\n",
    "                individuals = [offspring[i], non_dominated_parent]\n",
    "                ri_vs_p1 = self.dominance_comparison(individuals)\n",
    "                if(ri_vs_p1):\n",
    "                    self.n_penalty[op_idx] += 1\n",
    "                else:\n",
    "                    self.n_reward[op_idx] += 1\n",
    "        else:\n",
    "            for i in range(2):\n",
    "                individuals = [offspring[i], parents[0]]\n",
    "                ri_vs_p1 = self.dominance_comparison(individuals)\n",
    "                individuals = [offspring[i], parents[1]]\n",
    "                ri_vs_p2 = self.dominance_comparison(individuals)\n",
    "                if((not ri_vs_p1) and (not ri_vs_p2)):\n",
    "                    self.n_reward[op_idx] += 1\n",
    "                else:\n",
    "                    self.n_penalty[op_idx] += 1\n",
    "\n",
    "    def non_dominating_curve_plotter(self):\n",
    "        plt.figure(figsize=(6,5))\n",
    "        PF = self.fast_non_dominated_sort(self.objective1_values, self.objective2_values)\n",
    "        plt.xlabel('Solution size', fontsize=9)\n",
    "        plt.ylabel('Classification error', fontsize=9)\n",
    "        for idx in PF[0]:\n",
    "            plt.scatter(self.objective2_values[idx], self.objective1_values[idx], c='red', marker=\"*\", s=25)\n",
    "        plt.show()\n",
    "\n",
    "    def fit(self):\n",
    "        # self.population = self.init_pop()\n",
    "        RD = np.zeros((self.Q, self.LP))\n",
    "        PN = np.zeros((self.Q, self.LP))\n",
    "        self.n_reward = np.zeros(self.Q, dtype=int)\n",
    "        self.n_penalty = np.zeros(self.Q, dtype=int)\n",
    "        \n",
    "        pops = []\n",
    "        fitness_values_total = []\n",
    "        # pops = np.array([]).reshape(0, self.d)\n",
    "        for r_count in range(1):\n",
    "            print(f\"Run ({r_count})\")\n",
    "            self.population = self.init_pop()\n",
    "            self.OSP = [1/self.Q for _ in range(self.Q)]\n",
    "            self.generation_count = 0\n",
    "            self.nFE = 0\n",
    "            k = 0\n",
    "            while self.nFE < self.max_nFE:\n",
    "                self.generation_seed = np.random.randint(0, 4294967295, dtype=np.int64)\n",
    "                self.objective1_values = [self.score_individual_1(individual) for individual in self.population]\n",
    "                self.objective2_values = [self.score_individual_2(individual) for individual in self.population]\n",
    "                PF = self.fast_non_dominated_sort(self.objective1_values, self.objective2_values)\n",
    "                print('Best Individuals in Front-1 for Generation:', self.generation_count)\n",
    "                for idx in PF[0]:\n",
    "                    print(self.population[idx], end='')\n",
    "                    print(f\", O1: {self.score_individual_1(self.population[idx])} \", end='')\n",
    "                    print(f\"| O2: {self.score_individual_2(self.population[idx])}\")\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                pop = np.array(self.population)\n",
    "                fitness_values = self.evaluation(pop)\n",
    "                index = np.arange(pop.shape[0]).astype(int)\n",
    "                pareto_front_index = self.pareto_front_finding(fitness_values, index)\n",
    "                # pop = pop[pareto_front_index, :]\n",
    "                # fitness_values = fitness_values[pareto_front_index]\n",
    "                print('Best Individuals in Front-1 for Generation:', self.generation_count)\n",
    "                for idx in pareto_front_index:\n",
    "                    print(pop[idx], end='')\n",
    "                    print(f\", O1: {fitness_values[idx, 0]} \", end='')\n",
    "                    print(f\"| O2: {fitness_values[idx, 1]}\")\n",
    "                print(\"\\n\")\n",
    "                new_population = np.array(self.population[:])\n",
    "\n",
    "                for i in range(int(self.pop_size/2)):\n",
    "                    # Selecting operator using roulette wheel selection\n",
    "                    operator_idx = np.random.choice(range(0, self.Q), p=self.OSP)\n",
    "                    # Randomly select two individuals as parents\n",
    "                    parents_idx = np.random.choice(range(0, self.pop_size), 2)\n",
    "                    parents = [self.population[idx] for idx in parents_idx]\n",
    "                    # Crossover\n",
    "                    offspirng = self.crossover(parents, operator_idx)\n",
    "                    # Mutation\n",
    "                    mutated_offspring = [self.mutation(individual) for individual in offspirng]\n",
    "                    self.credit_assigment(parents, offspirng, operator_idx)\n",
    "                    \n",
    "                    # np.append(new_population, mutated_offspring)\n",
    "                    new_population = np.concatenate((new_population, mutated_offspring))\n",
    "                    # new_population += mutated_offspring\n",
    "                    self.nFE += 2\n",
    "                    \n",
    "                RD[k, :] = self.n_reward\n",
    "                PN[k, :] = self.n_penalty\n",
    "                self.n_reward = np.zeros(self.Q, dtype=int)\n",
    "                self.n_penalty = np.zeros(self.Q, dtype=int)\n",
    "                k += 1\n",
    "                if(k == self.LP):\n",
    "                    self.update_OSP(RD, PN)\n",
    "                    k = 0 \n",
    "\n",
    "                objective1_values = [self.score_individual_1(individual) for individual in new_population]\n",
    "                objective2_values = [self.score_individual_2(individual) for individual in new_population]\n",
    "                non_dominated_sorted_solutions = self.fast_non_dominated_sort(objective1_values[:], objective2_values[:])\n",
    "                crowding_distance_values2=[]\n",
    "                for i in range(len(non_dominated_sorted_solutions)):\n",
    "                    crowding_distance_values2.append(self.crowding_distance(objective1_values[:], objective2_values[:], \\\n",
    "                                                                            non_dominated_sorted_solutions[i][:]))\n",
    "                new_solution= []\n",
    "                for i in range(len(non_dominated_sorted_solutions)):\n",
    "                    non_dominated_sorted_solution2_1 = [self.index_locator(non_dominated_sorted_solutions[i][j],\\\n",
    "                                                                           non_dominated_sorted_solutions[i] ) \\\n",
    "                                                                            for j in range(0, len(non_dominated_sorted_solutions[i]))]\n",
    "                    front22 = self.sort_by_values(non_dominated_sorted_solution2_1[:], crowding_distance_values2[i][:])\n",
    "                    front = [non_dominated_sorted_solutions[i][front22[j]] for j in range(0, len(non_dominated_sorted_solutions[i]))]\n",
    "                    front.reverse()\n",
    "                    for value in front:\n",
    "                        new_solution.append(value)\n",
    "                        if(len(new_solution) == self.pop_size):\n",
    "                            break\n",
    "                    if (len(new_solution) == self.pop_size):\n",
    "                        break\n",
    "                self.population = [new_population[i] for i in new_solution]\n",
    "                \n",
    "                self.generation_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\Abbas Mrb\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Abbas Mrb/AppData/Local/Programs/Python/Python39/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mobga_ds2 = MOBGA_AOS(max_nFE = 3000)\n",
    "mobga_ds2.load_data('DS02.csv')\n",
    "mobga_ds2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\Abbas Mrb\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Abbas Mrb/AppData/Local/Programs/Python/Python39/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mobga_ds2.non_dominating_curve_plotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\Abbas Mrb\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Abbas Mrb/AppData/Local/Programs/Python/Python39/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mobga_ds3 = MOBGA_AOS(max_nFE = 4000)\n",
    "mobga_ds3.load_data('DS03.csv')\n",
    "mobga_ds3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\Abbas Mrb\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Abbas Mrb/AppData/Local/Programs/Python/Python39/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mobga_ds3.non_dominating_curve_plotter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d9bec1bd0dd1d60d9f041927d73dc99a1ae836019e05c066f33f67e6a94d9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
