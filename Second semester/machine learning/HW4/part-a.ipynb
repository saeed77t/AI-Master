{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from HDDT import HDDT\n",
    "from utils import perform_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_minority_vs_rest(X, y):\n",
    "    y = np.array(y)\n",
    "    \n",
    "    unique_labels, label_counts = np.unique(y, return_counts=True)\n",
    "    minority_class = unique_labels[np.argmin(label_counts)]\n",
    "    \n",
    "    binary_labels = np.where(y == minority_class, 1, 0)\n",
    "    \n",
    "    return X, binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"Covid19HDDT.csv\")\n",
    "# X = data.iloc[:, :-1]\n",
    "# y = data.iloc[:, -1]\n",
    "# X_minor, y_minor = separate_minority_class(X, y)\n",
    "# new_data = np.hstack((X_minor, y_minor.reshape((-1, 1))))\n",
    "# data = pd.DataFrame(new_data)\n",
    "\n",
    "# correlations = np.array(data.corrwith(data.iloc[:, -1], method=\"kendall\"))[:-1]\n",
    "# print(f\"Correlations with TARGET:\\n\", data.corrwith(data.iloc[:, -1], method=\"kendall\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv(\"Covid19HDDT.csv\"))\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing high correlations (maximum hellinger distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_hellinger_distance(X, y, feature):\n",
    "    f_vals = np.unique(X[:, feature])\n",
    "    hellinger_value = 0\n",
    "\n",
    "    for val in f_vals:\n",
    "        hellinger_value += (np.sqrt(X[(X[:, feature] == val) & (y == 1)].shape[0]/X[y == 1].shape[0]) - \\\n",
    "                            np.sqrt(X[(X[:, feature] == val) & (y == 0)].shape[0]/X[y == 0].shape[0]))**2\n",
    "    \n",
    "    return np.sqrt(hellinger_value)\n",
    "\n",
    "h_dists = []\n",
    "X_minor, y_minor = select_minority_vs_rest(X, y)\n",
    "for feature in range(X_minor.shape[1]):   \n",
    "    h_dists.append(calc_hellinger_distance(X_minor, y_minor, feature))\n",
    "\n",
    "selected = np.where(np.array(h_dists) < 1)[0]\n",
    "X = X[:, selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def undersample(X, y):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    min_samples = np.min(counts)\n",
    "\n",
    "    X_new = None\n",
    "    y_new = None\n",
    "    for i, v in enumerate(values):\n",
    "        idxs = np.random.choice(np.where(y == v)[0], min_samples)\n",
    "        if(i == 0):\n",
    "            X_new = X[idxs]\n",
    "            y_new = y[idxs]\n",
    "        else:\n",
    "            X_new = np.concatenate((X_new, X[idxs]),axis=0)\n",
    "            y_new = np.concatenate((y_new, y[idxs]),axis=0)\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minority vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Evaluation Metrics:\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n",
      "| max_depth | cut_off_size | Precision (Mean) | Recall (Mean) | F-measure (Mean) | G-mean (Mean) | AUC (Mean) | Accuracy (Mean) |\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n",
      "|     2     |      10      |      0.6282      |     0.6492    |      0.6385      |     0.7924    |   0.8081   |      0.942      |\n",
      "|     2     |      50      |      0.6282      |     0.6492    |      0.6385      |     0.7924    |   0.8081   |      0.942      |\n",
      "|     2     |     100      |      0.6282      |     0.6492    |      0.6385      |     0.7924    |   0.8081   |      0.942      |\n",
      "|     3     |      10      |      0.6425      |     0.915     |      0.7549      |     0.9355    |   0.9357   |      0.9532     |\n",
      "|     3     |      50      |      0.6425      |     0.915     |      0.7549      |     0.9355    |   0.9357   |      0.9532     |\n",
      "|     3     |     100      |      0.6425      |     0.915     |      0.7549      |     0.9355    |   0.9357   |      0.9532     |\n",
      "|     4     |      10      |      0.748       |     0.8708    |      0.8048      |     0.9214    |   0.9229   |      0.9667     |\n",
      "|     4     |      50      |      0.748       |     0.8683    |      0.8037      |     0.9201    |   0.9216   |      0.9666     |\n",
      "|     4     |     100      |      0.7511      |     0.8675    |      0.8051      |     0.9199    |   0.9214   |      0.9669     |\n",
      "|     5     |      10      |      0.8326      |     0.8042    |      0.8181      |     0.8905    |   0.8952   |      0.9718     |\n",
      "|     5     |      50      |      0.833       |     0.8025    |      0.8175      |     0.8896    |   0.8944   |      0.9717     |\n",
      "|     5     |     100      |      0.8118      |     0.8125    |      0.8122      |     0.8941    |   0.8982   |      0.9704     |\n",
      "|    None   |      10      |      0.8301      |     0.8142    |      0.822       |     0.8959    |    0.9     |      0.9722     |\n",
      "|    None   |      50      |      0.8313      |     0.8092    |      0.8201      |     0.8932    |   0.8976   |      0.972      |\n",
      "|    None   |     100      |      0.8082      |     0.8217    |      0.8149      |     0.8989    |   0.9025   |      0.9706     |\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_minor, y_minor = X_minor, y_minor = select_minority_vs_rest(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_minor, y_minor, stratify=y_minor, test_size=0.3, random_state=2)\n",
    "\n",
    "classifier = HDDT()\n",
    "param_grid = {'max_depth': [2, 3, 4, 5, None], 'cut_off_size': [10, 50, 100]}\n",
    "\n",
    "# Perform grid search\n",
    "perform_grid_search(classifier, param_grid, X_train, y_train, X_test, y_test, print_std=False, n_iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to find the most common element in a 1D array\n",
    "def find_most_common(column):\n",
    "    non_none_elements = column[column != None]\n",
    "    unique_elements, counts = np.unique(non_none_elements, return_counts=True)\n",
    "    if len(unique_elements) == 0:\n",
    "        return None\n",
    "    most_common_index = np.argmax(counts)\n",
    "    return unique_elements[most_common_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OVO_HDDT:\n",
    "    def __init__(self, max_depth=2, cut_off_size=1) -> None:\n",
    "        self.models = []\n",
    "        self.max_depth = max_depth\n",
    "        self.cut_off_size = cut_off_size\n",
    "\n",
    "    def select_OVO(self, X, y, l1, l2):\n",
    "        _X = X[(y == l1) | (y == l2), :]\n",
    "        _y = y[(y == l1) | (y == l2)]\n",
    "        _y[_y == l1] = 0\n",
    "        _y[_y == l2] = 1\n",
    "\n",
    "        return _X, _y\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        classes = np.unique(y)\n",
    "        self.models = []\n",
    "        for i in range(len(classes)):\n",
    "            for j in range(i + 1, len(classes)):\n",
    "                # print(f\"Class {i} vs. {j}\")\n",
    "                # X_train_, y_train_ = undersample(X_train, y_train)\n",
    "                _X, _y = self.select_OVO(X, y, i, j)\n",
    "\n",
    "                hddt = HDDT(max_depth=self.max_depth, cut_off_size=self.cut_off_size)\n",
    "                hddt.fit(_X, _y)\n",
    "                self.models.append(([i, j], hddt))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([])\n",
    "        for i, model in enumerate(self.models):\n",
    "            y_preds = np.array(model[1].predict(X))\n",
    "            cls_0 = np.where(y_preds == 0)[0]\n",
    "            cls_1 = np.where(y_preds == 1)[0]\n",
    "            y_preds[cls_0] = model[0][0]\n",
    "            y_preds[cls_1] = model[0][1]\n",
    "\n",
    "            if(i == 0):\n",
    "                predictions = y_preds\n",
    "            else:\n",
    "                predictions = np.vstack((predictions, y_preds))\n",
    "\n",
    "        y_pred = np.apply_along_axis(find_most_common, axis=0, arr=predictions)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Evaluation Metrics:\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n",
      "| max_depth | cut_off_size | Precision (Mean) | Recall (Mean) | F-measure (Mean) | G-mean (Mean) | AUC (Mean) | Accuracy (Mean) |\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n",
      "|     2     |      10      |      0.5786      |      1.0      |      0.733       |     0.9683    |   0.9688   |      0.9426     |\n",
      "|     2     |      50      |      0.5786      |      1.0      |      0.733       |     0.9683    |   0.9688   |      0.9426     |\n",
      "|     2     |     100      |      0.5786      |      1.0      |      0.733       |     0.9683    |   0.9688   |      0.9426     |\n",
      "|     3     |      10      |      0.7528      |     0.8475    |      0.7973      |     0.9096    |   0.9118   |      0.966      |\n",
      "|     3     |      50      |      0.7528      |     0.8475    |      0.7973      |     0.9096    |   0.9118   |      0.966      |\n",
      "|     3     |     100      |      0.7528      |     0.8475    |      0.7973      |     0.9096    |   0.9118   |      0.966      |\n",
      "|     4     |      10      |      0.8065      |     0.7817    |      0.7939      |     0.877     |   0.8828   |      0.968      |\n",
      "|     4     |      50      |      0.8069      |      0.78     |      0.7932      |     0.8761    |   0.882    |      0.9679     |\n",
      "|     4     |     100      |      0.7978      |     0.7892    |      0.7935      |     0.8807    |   0.886    |      0.9676     |\n",
      "|     5     |      10      |      0.8314      |     0.7683    |      0.7986      |     0.8707    |   0.8775   |      0.9694     |\n",
      "|     5     |      50      |      0.8294      |      0.77     |      0.7986      |     0.8715    |   0.8782   |      0.9694     |\n",
      "|     5     |     100      |      0.8126      |     0.7842    |      0.7981      |     0.8787    |   0.8843   |      0.9687     |\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "classifier = OVO_HDDT()\n",
    "param_grid = {'max_depth': [2, 3, 4, 5], 'cut_off_size': [10, 50, 100]}\n",
    "\n",
    "# Perform grid search\n",
    "perform_grid_search(classifier, param_grid, X_train, y_train, X_test, y_test, print_std=False, n_iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OVA_HDDT:\n",
    "    def __init__(self, max_depth=2, cut_off_size=1) -> None:\n",
    "        self.models = []\n",
    "        self.max_depth = max_depth\n",
    "        self.cut_off_size = cut_off_size\n",
    "\n",
    "    def select_OVA(self, X, y, l):\n",
    "        _y = np.select([y == l, y != l], [1, 0], y)\n",
    "        return X, _y\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        classes = np.unique(y)\n",
    "        self.models = []\n",
    "        for i in range(len(classes)):\n",
    "            # print(f\"Class {i} vs. All\")\n",
    "            # X_train_, y_train_ = undersample(X_train, y_train)\n",
    "            _X, _y = self.select_OVA(X, y, i)\n",
    "\n",
    "            hddt = HDDT(max_depth=self.max_depth, cut_off_size=self.cut_off_size)\n",
    "            hddt.fit(_X, _y)\n",
    "            self.models.append((i, hddt))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([])\n",
    "        for i, model in enumerate(self.models):\n",
    "            y_pred_probs = model[1].predict_prob(X)\n",
    "            y_pred_probs = [pred[1] for pred in y_pred_probs]\n",
    "\n",
    "            if(i == 0):\n",
    "                predictions = y_pred_probs\n",
    "            else:\n",
    "                predictions = np.vstack((predictions, y_pred_probs))\n",
    "\n",
    "        y_pred = np.apply_along_axis(np.argmax, axis=0, arr=predictions)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Evaluation Metrics:\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n",
      "| max_depth | cut_off_size | Precision (Mean) | Recall (Mean) | F-measure (Mean) | G-mean (Mean) | AUC (Mean) | Accuracy (Mean) |\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n",
      "|     2     |      10      |      0.6423      |     0.6358    |      0.639       |     0.7852    |   0.8028   |      0.9434     |\n",
      "|     2     |      50      |      0.6423      |     0.6358    |      0.639       |     0.7852    |   0.8028   |      0.9434     |\n",
      "|     2     |     100      |      0.6423      |     0.6358    |      0.639       |     0.7852    |   0.8028   |      0.9434     |\n",
      "|     3     |      10      |      0.6372      |      0.9      |      0.7461      |     0.9276    |   0.9281   |      0.9517     |\n",
      "|     3     |      50      |      0.6372      |      0.9      |      0.7461      |     0.9276    |   0.9281   |      0.9517     |\n",
      "|     3     |     100      |      0.6372      |      0.9      |      0.7461      |     0.9276    |   0.9281   |      0.9517     |\n",
      "|     4     |      10      |      0.7268      |     0.9092    |      0.8078      |     0.9395    |    0.94    |      0.9659     |\n",
      "|     4     |      50      |      0.7259      |     0.905     |      0.8056      |     0.9373    |   0.9379   |      0.9656     |\n",
      "|     4     |     100      |      0.7202      |     0.9075    |      0.8031      |     0.9381    |   0.9387   |      0.9649     |\n",
      "|     5     |      10      |      0.8287      |      0.77     |      0.7983      |     0.8715    |   0.8782   |      0.9693     |\n",
      "|     5     |      50      |      0.8294      |      0.77     |      0.7986      |     0.8715    |   0.8782   |      0.9694     |\n",
      "|     5     |     100      |      0.8126      |     0.7842    |      0.7981      |     0.8787    |   0.8843   |      0.9687     |\n",
      "+-----------+--------------+------------------+---------------+------------------+---------------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "classifier = OVA_HDDT()\n",
    "param_grid = {'max_depth': [2, 3, 4, 5], 'cut_off_size': [10, 50, 100]}\n",
    "\n",
    "# Perform grid search\n",
    "perform_grid_search(classifier, param_grid, X_train, y_train, X_test, y_test, print_std=False, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ffc2c986650f75bb84df5ef0f5794d173c138677d61245fd2c4ff2debf2f2371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
