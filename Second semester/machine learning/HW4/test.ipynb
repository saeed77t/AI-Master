{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging:\n",
    "    def __init__(self, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Create a base learner\n",
    "            base_estimator = DecisionTreeClassifier()\n",
    "            # Randomly sample the training data with replacement\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_subset, y_subset = X[indices], y[indices]\n",
    "            # Train the base learner on the sampled data\n",
    "            base_estimator.fit(X_subset, y_subset)\n",
    "            # Add the trained base learner to the list of estimators\n",
    "            self.estimators.append(base_estimator)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions for each base learner and aggregate the results\n",
    "        predictions = np.array([estimator.predict(X) for estimator in self.estimators])\n",
    "        # Take the majority vote as the final prediction\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggingWithUndersampling:\n",
    "    def __init__(self, n_estimators=10, max_samples=1.0, max_features=1.0, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Create a base learner\n",
    "            base_estimator = DecisionTreeClassifier(max_features=self.max_features, random_state=self.random_state)\n",
    "            # Randomly sample the training data with replacement and undersampling\n",
    "            minority_class_indices = np.where(y == 1)[0]\n",
    "            majority_class_indices = np.where(y == 0)[0]\n",
    "            majority_class_indices_sampled = np.random.choice(majority_class_indices, int(len(minority_class_indices) * self.max_samples), replace=False)\n",
    "            indices = np.concatenate((minority_class_indices, majority_class_indices_sampled))\n",
    "            X_subset, y_subset = X[indices], y[indices]\n",
    "            # Train the base learner on the sampled data\n",
    "            base_estimator.fit(X_subset, y_subset)\n",
    "            # Add the trained base learner to the list of estimators\n",
    "            self.estimators.append(base_estimator)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions for each base learner and aggregate the results\n",
    "        predictions = np.array([estimator.predict(X) for estimator in self.estimators])\n",
    "        # Take the majority vote as the final prediction\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "class AdaBoostWithUndersampling:\n",
    "    def __init__(self, n_estimators=10, max_depth=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators = []\n",
    "        self.estimator_weights = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        sample_weights = np.full(n_samples, (1 / n_samples))\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            # Create a base learner\n",
    "            base_estimator = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            # Randomly sample the training data based on the sample weights\n",
    "            minority_class_indices = np.where(y == 1)[0]\n",
    "            majority_class_indices = np.where(y == 0)[0]\n",
    "            majority_class_indices_sampled = np.random.choice(majority_class_indices, len(minority_class_indices), replace=False)\n",
    "            indices = np.concatenate((minority_class_indices, majority_class_indices_sampled))\n",
    "            X_subset, y_subset, sample_weights_subset = X[indices], y[indices], sample_weights[indices]\n",
    "            # Train the base learner on the sampled data\n",
    "            base_estimator.fit(X_subset, y_subset, sample_weight=sample_weights_subset)\n",
    "            # Make predictions on the training data\n",
    "            predictions = base_estimator.predict(X)\n",
    "            # Calculate the weighted error\n",
    "            weighted_error = np.sum(sample_weights * (predictions != y))\n",
    "            # Calculate the estimator weight\n",
    "            estimator_weight = 0.5 * np.log((1 - weighted_error) / weighted_error)\n",
    "            # Update the sample weights\n",
    "            sample_weights *= np.exp(estimator_weight * (predictions != y))\n",
    "            # Normalize the sample weights\n",
    "            sample_weights /= np.sum(sample_weights)\n",
    "            # Add the trained base learner and its weight to the list of estimators and estimator weights\n",
    "            self.estimators.append(base_estimator)\n",
    "            self.estimator_weights.append(estimator_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([estimator.predict(X) for estimator in self.estimators])\n",
    "        # Weighted majority vote\n",
    "        weighted_votes = np.sum(predictions.T * self.estimator_weights, axis=1)\n",
    "        # Convert weighted votes to binary predictions\n",
    "        binary_predictions = np.where(weighted_votes >= 0.5 * np.sum(self.estimator_weights), 1, 0)\n",
    "        return binary_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
