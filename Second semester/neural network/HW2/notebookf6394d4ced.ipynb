{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ad1231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "# from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5202d-2471-42ae-8532-711890fd6f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ef519a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_csv('Dataset/Text_Emotion_Data.csv')\n",
    "\n",
    "# Define a function to tokenize text into word sequences and remove stopwords\n",
    "def tokenize_text(text):\n",
    "    # Remove non-letter characters using the defined pattern\n",
    "    pattern = r'[^a-zA-Z]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text into word sequences\n",
    "    word_sequences = text.split()\n",
    "    # Remove stopwords using the provided list\n",
    "    with open('Dataset/stopwords.txt', 'r') as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "    # Remove words with length less than or equal to 2\n",
    "    word_sequences = [word for word in word_sequences if (word not in stopwords and len(word) > 2)]\n",
    "    return word_sequences\n",
    "\n",
    "# Tokenize each row of the text column into word sequences using the defined function\n",
    "df['word_sequences'] = df['Text'].apply(tokenize_text)\n",
    "\n",
    "# Find the maximum length of a word sequence\n",
    "max_len = max(df['word_sequences'].apply(len))\n",
    "\n",
    "# Define a function to pad the sequences to the maximum length\n",
    "def pad_sequence(sequence):\n",
    "    padded_sequence = sequence[:max_len] + ['']*(max_len-len(sequence))\n",
    "    return padded_sequence\n",
    "\n",
    "# Pad each sequence to the maximum length\n",
    "df['word_sequences'] = df['word_sequences'].apply(pad_sequence)\n",
    "\n",
    "# Combine all word sequences into a single list\n",
    "all_sequences = []\n",
    "for seq in df['word_sequences']:\n",
    "    all_sequences.append(seq)\n",
    "\n",
    "# Create a dictionary with unique words as keys and their corresponding index as values\n",
    "word_dict = {}\n",
    "index = 0\n",
    "for seq in all_sequences:\n",
    "    for word in seq:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = index\n",
    "            index += 1\n",
    "\n",
    "# Convert each word sequence into a numerical vector with the corresponding index in the dictionary\n",
    "num_vectors = []\n",
    "for sequence in all_sequences:\n",
    "    vector = []\n",
    "    for word in sequence:\n",
    "        if word in word_dict:\n",
    "            index = word_dict[word]\n",
    "            vector.append(index)\n",
    "    num_vectors.append(vector)\n",
    "\n",
    "# Convert the list of numerical vectors into a numpy array\n",
    "X = np.array(num_vectors)\n",
    "\n",
    "# Define the labels\n",
    "labels = df['Label'].values\n",
    "classes = np.unique(labels)\n",
    "label_map = {label: i for i, label in enumerate(classes)}\n",
    "y = np.array([label_map[label] for label in labels])\n",
    "\n",
    "# Split last 150 text of each class for the test dataset\n",
    "test_data = []\n",
    "for c in classes:\n",
    "    class_data = [(X[i], y[i]) for i in range(len(X)) if y[i] == label_map[c]]\n",
    "    test_data.extend(class_data[-150:])\n",
    "\n",
    "# Use the rest of the data for training\n",
    "train_data = []\n",
    "for i in range(len(X)):\n",
    "    found = False\n",
    "    for j in range(len(test_data)):\n",
    "        if all(X[i] == test_data[j][0]) and y[i] == test_data[j][1]:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        train_data.append((X[i], y[i]))\n",
    "\n",
    "# Separate the input features and labels for the training and test sets\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c5cef9-0d10-48f8-a1bd-77d80e83ff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>word_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i now feel like im finally in a position to de...</td>\n",
       "      <td>joy</td>\n",
       "      <td>[now, feel, like, finally, position, decide, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel resigned to my lot in life being that i...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[feel, resigned, lot, life, being, that, watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel thrilled with your presence in your eye...</td>\n",
       "      <td>joy</td>\n",
       "      <td>[feel, thrilled, with, your, presence, your, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i may finally sit down and feel sweet release ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>[may, finally, sit, down, and, feel, sweet, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel a bit jealous because i been trying to ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[feel, bit, jealous, because, been, trying, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>i just want to say all the things i want to sa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[just, want, say, all, the, things, want, say,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>i feel that i need to be more generous with my...</td>\n",
       "      <td>love</td>\n",
       "      <td>[feel, that, need, more, generous, with, offer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>im sitting here in the belmont library listeni...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[sitting, here, the, belmont, library, listeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>i can t let go of that sad feeling that i want...</td>\n",
       "      <td>love</td>\n",
       "      <td>[can, let, that, sad, feeling, that, want, acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>i feel so pathetic that i stoop down to that l...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[feel, pathetic, that, stoop, down, that, leve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3250 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text    Label  \\\n",
       "0     i now feel like im finally in a position to de...      joy   \n",
       "1     i feel resigned to my lot in life being that i...  sadness   \n",
       "2     i feel thrilled with your presence in your eye...      joy   \n",
       "3     i may finally sit down and feel sweet release ...      joy   \n",
       "4     i feel a bit jealous because i been trying to ...    anger   \n",
       "...                                                 ...      ...   \n",
       "3245  i just want to say all the things i want to sa...  sadness   \n",
       "3246  i feel that i need to be more generous with my...     love   \n",
       "3247  im sitting here in the belmont library listeni...  sadness   \n",
       "3248  i can t let go of that sad feeling that i want...     love   \n",
       "3249  i feel so pathetic that i stoop down to that l...  sadness   \n",
       "\n",
       "                                         word_sequences  \n",
       "0     [now, feel, like, finally, position, decide, w...  \n",
       "1     [feel, resigned, lot, life, being, that, watch...  \n",
       "2     [feel, thrilled, with, your, presence, your, e...  \n",
       "3     [may, finally, sit, down, and, feel, sweet, re...  \n",
       "4     [feel, bit, jealous, because, been, trying, da...  \n",
       "...                                                 ...  \n",
       "3245  [just, want, say, all, the, things, want, say,...  \n",
       "3246  [feel, that, need, more, generous, with, offer...  \n",
       "3247  [sitting, here, the, belmont, library, listeni...  \n",
       "3248  [can, let, that, sad, feeling, that, want, acc...  \n",
       "3249  [feel, pathetic, that, stoop, down, that, leve...  \n",
       "\n",
       "[3250 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3db89073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (2500, 27)\n",
      "X_test shape : (750, 27)\n",
      "y_train shape : (2500,)\n",
      "y_test shape : (750,)\n",
      "word_dict len : 6623\n",
      "max_len  : 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([203,  65, 204,  10, 205,   2,  19, 206, 207, 133, 208, 176, 209,\n",
       "       210,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,\n",
       "        15])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('X_test shape :' ,X_test.shape)\n",
    "print('y_train shape :' ,y_train.shape)\n",
    "print('y_test shape :', y_test.shape)\n",
    "print('word_dict len :', len(word_dict))\n",
    "print('max_len  :' ,max_len) \n",
    "X_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad75217d-afbc-44c2-ac15-6485ad5ff7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([203,  65, 204,  10, 205,   2,  19, 206, 207, 133, 208, 176, 209,\n",
       "       210,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,\n",
       "        15])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "646319f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape the input data to have a third dimension\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# Convert y_train to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=5)\n",
    "y_test= to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cb79c74-b679-4be0-a441-dc8071dc0712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (2500, 27, 1)\n",
      "X_test shape : (750, 27, 1)\n",
      "y_train shape : (2500, 5)\n",
      "y_test shape : (750, 5)\n",
      "word_dict len : 6623\n",
      "max_len  : 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[203],\n",
       "       [ 65],\n",
       "       [204],\n",
       "       [ 10],\n",
       "       [205],\n",
       "       [  2],\n",
       "       [ 19],\n",
       "       [206],\n",
       "       [207],\n",
       "       [133],\n",
       "       [208],\n",
       "       [176],\n",
       "       [209],\n",
       "       [210],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15],\n",
       "       [ 15]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('X_test shape :' ,X_test.shape)\n",
    "print('y_train shape :' ,y_train.shape)\n",
    "print('y_test shape :', y_test.shape)\n",
    "print('word_dict len :', len(word_dict))\n",
    "print('max_len  :' ,max_len) \n",
    "X_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "475c53b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/gv/29bx0dbj5fvf2ql1sq4xwxsh0000gn/T/ipykernel_91652/2009924155.py\", line 13, in <cell line: 13>\n      model.fit(X_train, y_train, epochs=1000, batch_size=32)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,5] and labels shape [160]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_38593]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the train dataset\u001b[39;00m\n\u001b[1;32m     16\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_train, y_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/gv/29bx0dbj5fvf2ql1sq4xwxsh0000gn/T/ipykernel_91652/2009924155.py\", line 13, in <cell line: 13>\n      model.fit(X_train, y_train, epochs=1000, batch_size=32)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/saeed/opt/anaconda3/lib/python3.9/site-packages/keras/backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,5] and labels shape [160]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_38593]"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(max_len, 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the train dataset\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Loss:', train_loss)\n",
    "print('Train Accuracy:', train_acc)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d36a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd02e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49013dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99062e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8dcd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96493c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf9a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a622ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd28ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82184abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3c7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479394cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1812f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
