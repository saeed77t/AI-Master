{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from activation_func import activation_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "x                   z_in           z                y_in     y\n",
      "------------------  -------------  -------------  ------  ----\n",
      "[[0.25 0.5  0.75]]  [[0.75 0.75]]  [[0.36 0.36]]    0.36  0.36\n",
      "[[0.75 0.5  0.25]]  [[0.75 0.75]]  [[0.36 0.36]]    0.36  0.36\n",
      "δ_H                δ_O  h(q)             o(q)\n",
      "---------------  -----  ---------------  ---------\n",
      "[[-0.01 -0.01]]  -0.04  [[-0.   -0.  ]   [[-0.01]\n",
      "                         [-0.   -0.  ]    [-0.01]]\n",
      "                         [-0.01 -0.01]]\n",
      "[[-0.06 -0.06]]  -0.28  [[-0.05 -0.05]   [[-0.1]\n",
      "                         [-0.03 -0.03]    [-0.1]]\n",
      "                         [-0.02 -0.02]]\n",
      "o = [[-0.11]\n",
      " [-0.11]]\n",
      "h = [[-0.05 -0.05]\n",
      " [-0.03 -0.03]\n",
      " [-0.02 -0.02]]\n",
      "Δv = [[0.02 0.02]\n",
      " [0.02 0.02]\n",
      " [0.01 0.01]]\n",
      "Δw = [[0.06]\n",
      " [0.06]]\n",
      "v = [[0.52 0.52]\n",
      " [0.52 0.52]\n",
      " [0.51 0.51]]\n",
      "w = [[0.56]\n",
      " [0.56]]\n"
     ]
    }
   ],
   "source": [
    "from MLP_ULTRA import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "x                   z_in           z                  y_in      y\n",
      "------------------  -------------  ---------------  ------  -----\n",
      "[[0.25 0.5  0.75]]  [[0.75 0.75]]  [[0.358 0.358]]   0.358  0.358\n",
      "[[0.75 0.5  0.25]]  [[0.75 0.75]]  [[0.358 0.358]]   0.358  0.358\n",
      "δ_H                   δ_O  h(q)               o(q)\n",
      "-----------------  ------  -----------------  ---------\n",
      "[[0.024 0.024]]     0.108  [[0.006 0.006]     [[0.039]\n",
      "                            [0.012 0.012]      [0.039]]\n",
      "                            [0.018 0.018]]\n",
      "[[-0.085 -0.085]]  -0.392  [[-0.064 -0.064]   [[-0.14]\n",
      "                            [-0.043 -0.043]    [-0.14]]\n",
      "                            [-0.021 -0.021]]\n",
      "o = [[-0.102]\n",
      " [-0.102]]\n",
      "h = [[-0.058 -0.058]\n",
      " [-0.031 -0.031]\n",
      " [-0.004 -0.004]]\n",
      "Δv = [[0.029 0.029]\n",
      " [0.015 0.015]\n",
      " [0.002 0.002]]\n",
      "Δw = [[0.051]\n",
      " [0.051]]\n",
      "v = [[0.529 0.529]\n",
      " [0.515 0.515]\n",
      " [0.502 0.502]]\n",
      "w = [[0.551]\n",
      " [0.551]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.25, 0.5, 0.75], [0.75, 0.5, 0.25]])\n",
    "y = np.array([[0.25], [0.75]])\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 2\n",
    "output_size = y.shape[1]\n",
    "\n",
    "V = np.full((input_size, hidden_size), 0.5)\n",
    "# V = []\n",
    "W = np.full((hidden_size, output_size), 0.5)\n",
    "\n",
    "# V0 = np.full((1, hidden_size), 0.5)\n",
    "# W0 = np.full((1, output_size), 0.5)\n",
    "\n",
    "# V = np.vstack((V0, V))\n",
    "# W = np.vstack((W0, W))\n",
    "\n",
    "hidden_act = activation_func.bipolar_sigmoid\n",
    "de_hidden_act = activation_func.d_bipolar_sigmoid\n",
    "output_act = activation_func.identity\n",
    "de_output_act = activation_func.d_identity\n",
    "mlp = MLP(\n",
    "    input_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    activation_func_hidden=hidden_act,\n",
    "    activation_func_output=output_act,\n",
    "    derivative_act_hidden=de_hidden_act,\n",
    "    derivative_act_output=de_output_act,\n",
    "    batch_mode=True,\n",
    "    bias=False,\n",
    "    print_steps=True,\n",
    "    decimal_point=3,\n",
    "    init_weights=(V, W)\n",
    ")\n",
    "v,w = mlp.train(X, y, epochs=1, learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "x                   z_in       z                  y_in      y\n",
      "------------------  ---------  ---------------  ------  -----\n",
      "[[0.25 0.5  0.25]]  [[1. 1.]]  [[0.462 0.462]]   0.962  0.962\n",
      "[[0.5  0.25 0.5 ]]  [[1. 1.]]  [[0.462 0.462]]   0.303  0.303\n",
      "δ_H                 δ_O  Δv                 Δw          v                w\n",
      "---------------  ------  -----------------  ----------  ---------------  ---------\n",
      "[[0.091 0.091]]   0.462  [[-0.091 -0.091]   [[-0.462]   [[0.409 0.409]   [[0.038]\n",
      "                          [-0.023 -0.023]    [-0.214]    [0.477 0.477]    [0.286]\n",
      "                          [-0.045 -0.045]    [-0.214]]   [0.455 0.455]    [0.286]]\n",
      "                          [-0.023 -0.023]]               [0.477 0.477]]\n",
      "[[-0.05 -0.05]]  -0.447  [[0.05  0.05 ]     [[0.447]    [[0.46  0.46 ]   [[0.485]\n",
      "                          [0.025 0.025]      [0.207]     [0.502 0.502]    [0.493]\n",
      "                          [0.013 0.013]      [0.207]]    [0.467 0.467]    [0.493]]\n",
      "                          [0.025 0.025]]                 [0.502 0.502]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.25, 0.5, 0.25], [0.5, 0.25, 0.5]])\n",
    "y = np.array([[0.5], [0.75]])\n",
    "\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 2\n",
    "output_size = y.shape[1]\n",
    "\n",
    "V = np.full((input_size, hidden_size), 0.5)\n",
    "W = np.full((hidden_size, output_size), 0.5)\n",
    "\n",
    "V0 = np.full((1, hidden_size), 0.5)\n",
    "W0 = np.full((1, output_size), 0.5)\n",
    "\n",
    "V = np.vstack((V0, V))\n",
    "W = np.vstack((W0, W))\n",
    "\n",
    "hidden_act = activation_func.bipolar_sigmoid\n",
    "de_hidden_act = activation_func.d_bipolar_sigmoid\n",
    "output_act = activation_func.identity\n",
    "de_output_act = activation_func.d_identity\n",
    "mlp = MLP(\n",
    "    input_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    activation_func_hidden=hidden_act,\n",
    "    activation_func_output=output_act,\n",
    "    derivative_act_hidden=de_hidden_act,\n",
    "    derivative_act_output=de_output_act,\n",
    "    batch_mode=False,\n",
    "    bias=True,\n",
    "    print_steps=True,\n",
    "    decimal_point=3,\n",
    "    init_weights=(V, W)\n",
    ")\n",
    "v, w = mlp.train(X, y, epochs=1, learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "x             z_in           z              y_in           y\n",
      "------------  -------------  -------------  -------------  -------------\n",
      "[[1 1 1]]     [[1.48 1.33]]  [[0.63 0.58]]  [[0.67 1.52]]  [[0.32 0.64]]\n",
      "[[ 1 -1 -1]]  [[0.36 0.23]]  [[0.18 0.11]]  [[0.32 1.02]]  [[0.16 0.47]]\n",
      "δ_H              δ_O              Δv               Δw               v              w\n",
      "---------------  ---------------  ---------------  ---------------  -------------  -------------\n",
      "[[-0.1  -0.03]]  [[-0.3  -0.11]]  [[0.02 0.01]     [[0.06 0.02]     [[0.24 0.58]   [[0.15 0.83]\n",
      "                                   [0.02 0.01]      [0.04 0.01]      [0.72 0.22]    [0.81 0.87]\n",
      "                                   [0.02 0.01]      [0.04 0.01]]     [0.2  0.12]    [0.21 0.3 ]]\n",
      "                                   [0.02 0.01]]                      [0.4  0.45]]\n",
      "[[0.46 0.14]]    [[0.56 0.57]]    [[-0.09 -0.03]   [[-0.11 -0.11]   [[0.15 0.55]   [[0.04 0.72]\n",
      "                                   [-0.09 -0.03]    [-0.02 -0.02]    [0.63 0.19]    [0.79 0.85]\n",
      "                                   [ 0.09  0.03]    [-0.01 -0.01]]   [0.29 0.14]    [0.19 0.29]]\n",
      "                                   [ 0.09  0.03]]                    [0.49 0.47]]\n"
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "hidden_size = 2\n",
    "output_size = 2\n",
    "X = np.array([[1, 1, 1], [1, -1, -1]])\n",
    "y = np.array([[1, 1], [-1, -1]])\n",
    "\n",
    "V = np.array([\n",
    "    [0.22, 0.57],\n",
    "    [0.7, 0.21],\n",
    "    [0.18, 0.11],\n",
    "    [0.38, 0.44]\n",
    "])\n",
    "\n",
    "W = np.array([\n",
    "    [0.09, 0.81],\n",
    "    [0.77, 0.86],\n",
    "    [0.17, 0.29]\n",
    "])\n",
    "l\n",
    "\n",
    "hidden_act = activation_func.bipolar_sigmoid\n",
    "de_hidden_act = activation_func.d_bipolar_sigmoid\n",
    "output_act = activation_func.bipolar_sigmoid\n",
    "de_output_act = activation_func.d_bipolar_sigmoid\n",
    "\n",
    "mlp = MLP(\n",
    "    input_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    activation_func_hidden=hidden_act,\n",
    "    activation_func_output=output_act,\n",
    "    derivative_act_hidden=de_hidden_act,\n",
    "    derivative_act_output=de_output_act,\n",
    "    batch_mode=False,\n",
    "    bias=True,\n",
    "    print_steps=True,\n",
    "    init_weights=(V, W)\n",
    ")\n",
    "v, w = mlp.train(X, y, epochs=1, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_in(1) = -3.45\n",
      "Z_in(2) = -2.5\n",
      "Z_in(3) = -1.5\n",
      "Z_in(4) = -0.25\n",
      "Z_in(5) = 0.65\n",
      "Z_in(6) = 1.9\n",
      "Z_in = [-3.45 -2.5  -1.5  -0.25  0.65  1.9 ]\n",
      "After applying hidden layer activation function:\n",
      "Z = [0.   0.   0.   0.   0.65 1.9 ]\n",
      "Output after pooling:\n",
      "y = [0.   0.   1.27]\n",
      "out_H: [0.   0.   0.   0.   0.65 1.9 ]\n",
      "out_O: [0.   0.   1.27]\n"
     ]
    }
   ],
   "source": [
    "from activation_func import activation_func\n",
    "from pooling import pooling\n",
    "from convNet import convNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_in(1) = -3.45\n",
      "Z_in(2) = -2.5\n",
      "Z_in(3) = -1.5\n",
      "Z_in(4) = -0.25\n",
      "Z_in(5) = 0.65\n",
      "Z_in(6) = 1.9\n",
      "Z_in = [-3.45 -2.5  -1.5  -0.25  0.65  1.9 ]\n",
      "After applying hidden layer activation function:\n",
      "Z = [-0.968 -0.918 -0.777 -0.221  0.65   1.9  ]\n",
      "Output after pooling:\n",
      "y = [-0.943 -0.499  1.275]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-2.0, -1.8, -1.4, -0.6, -0.2, 0.4, 0.8, 1.6])\n",
    "\n",
    "conv_filter = np.array([0.75, 0.5, 0.75])\n",
    "\n",
    "conv1d = convNet(\n",
    "    conv_filter=conv_filter,\n",
    "    stride_conv=1,\n",
    "    pooling_type=pooling.average_pooling,\n",
    "    pooling_size=2,\n",
    "    stride_pooling=2,\n",
    "    decimal_point=3,\n",
    "    act_f=activation_func.Elu,\n",
    ")\n",
    "\n",
    "out_H, out_O = conv1d.forward(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_in(1) = -3.45\n",
      "Z_in(2) = -2.5\n",
      "Z_in(3) = -1.5\n",
      "Z_in(4) = -0.25\n",
      "Z_in(5) = 0.65\n",
      "Z_in(6) = 1.9\n",
      "Z_in = [-3.45 -2.5  -1.5  -0.25  0.65  1.9 ]\n",
      "After applying hidden layer activation function:\n",
      "Z = [-0.968 -0.918 -0.777 -0.221  0.65   1.9  ]\n",
      "Output after pooling:\n",
      "y = [-0.933 -0.388  1.525]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-2.0, -1.8, -1.4, -0.6, -0.2, 0.4, 0.8, 1.6])\n",
    "\n",
    "conv_filter = np.array([0.75, 0.5, 0.75,0.25])\n",
    "weights = [0.3, 0.7]\n",
    "\n",
    "conv1d = convNet(\n",
    "    conv_filter=conv_filter,\n",
    "    stride_conv=1,\n",
    "    pooling_type=pooling.weighted_pooling,\n",
    "    pooling_params=a,\n",
    "    pooling_size=2,\n",
    "    stride_pooling=2,\n",
    "    decimal_point=3,\n",
    "    act_f=activation_func.Elu,\n",
    ")\n",
    "\n",
    "out_H, out_O = conv1d.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ffc2c986650f75bb84df5ef0f5794d173c138677d61245fd2c4ff2debf2f2371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
