{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b2a8da-96fe-4105-976b-eb1461e134e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import torch\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82349aba-3fa6-49f5-a83e-4dd8f89e650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba952f7-a0ed-4dfc-91a3-65490e656256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the root folder of your dataset\n",
    "root_folder = \"MNIST Dataset/\"\n",
    "\n",
    "# Define lists to store the image data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Loop over the folders in the root folder\n",
    "for i in range(10):\n",
    "    folder_path = root_folder + str(i) + \"/\"\n",
    "\n",
    "    # Get the label corresponding to the folder name\n",
    "    label = i\n",
    "\n",
    "    # Loop over the images in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Read the image using OpenCV and convert it to grayscale\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Add the image and label to the dataset lists\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "# Convert the data and labels lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets, with 90% of each class for training\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for i in range(10):\n",
    "    class_data = data[labels == i]\n",
    "    class_labels = labels[labels == i]\n",
    "\n",
    "    train_class_data, test_class_data, train_class_labels, test_class_labels = train_test_split(class_data, class_labels, test_size=0.1)\n",
    "\n",
    "    train_data.append(train_class_data)\n",
    "    train_labels.append(train_class_labels)\n",
    "    test_data.append(test_class_data)\n",
    "    test_labels.append(test_class_labels)\n",
    "\n",
    "# Concatenate the training and testing data and labels for each class\n",
    "train_data = np.concatenate(train_data)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "test_data = np.concatenate(test_data)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "\n",
    "# Create a pandas dataframe to store the data and labels\n",
    "train_df = pd.DataFrame(train_data.reshape(train_data.shape[0], -1))\n",
    "train_df['label'] = train_labels\n",
    "\n",
    "test_df = pd.DataFrame(test_data.reshape(test_data.shape[0], -1))\n",
    "test_df['label'] = test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2ade43-7a7d-4d1f-b8ca-ad146022566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Train and Test  Data and labels\n",
    "TrainLabels = train_df['label']\n",
    "TrainData = train_df.drop('label',axis=1)\n",
    "TestLabels = test_df['label']\n",
    "TestData = test_df.drop('label',axis=1)\n",
    "TrainData = np.array(TrainData)\n",
    "TrainLabels = np.array(TrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e35c52-6699-47ed-a6a4-2fa278515c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ce7bb-7e1a-4644-828f-1c3e5a220017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "TrainData = TrainData\n",
    "TestData = TestData\n",
    "\n",
    "# Preprocess the dataset\n",
    "train_images = TrainData / 255.0\n",
    "test_images = TestData/ 255.0\n",
    "\n",
    "train_images = torch.DoubleTensor(train_images)\n",
    "# test_images = torch.DoubleTensor(test_images)\n",
    "\n",
    "\n",
    "train_labels = TrainLabels\n",
    "test_labels = TestLabels\n",
    "\n",
    "num_classes = 10  # number of classes in the dataset\n",
    "\n",
    "# Part 1: Build a SOM with one neuron for each class\n",
    "class SOM(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.weights = torch.nn.Parameter(torch.randn(num_classes, 784))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        # distances = torch.cdist(x, self.weights)\n",
    "        distances = torch.cdist(x.double(), self.weights.double())\n",
    "\n",
    "        winners = torch.argmin(distances, dim=1)\n",
    "        return winners\n",
    "\n",
    "# Part 2: Specify how many images of each class are placed in each cluster\n",
    "# and specify the label for each cluster\n",
    "s = SOM(num_classes)\n",
    "s.train()\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(zip(train_images, train_labels)):\n",
    "        # winner = s(images.unsqueeze(0))\n",
    "        winner = s(torch.tensor(images).unsqueeze(0))\n",
    "\n",
    "        s.weights[winner] += images.flatten() - s.weights[winner]\n",
    "\n",
    "# Compute the cluster sizes and labels\n",
    "cluster_sizes = torch.zeros(num_classes)\n",
    "cluster_labels = torch.zeros(num_classes)\n",
    "for i in range(num_classes):\n",
    "    indices = (s.weights == s.weights[i]).all(dim=1).nonzero().squeeze()\n",
    "    cluster_sizes[i] = indices.numel()\n",
    "    if indices.numel() == 0:\n",
    "        cluster_labels[i] = -1\n",
    "    else:\n",
    "        cluster_labels[i] = train_labels[indices[0]]\n",
    "\n",
    "# Print the cluster sizes and labels\n",
    "print('Cluster Sizes:', cluster_sizes)\n",
    "print('Cluster Labels:', cluster_labels)\n",
    "\n",
    "# Part 3: Compute Davies-Bouldin Index\n",
    "normalized_weights = s.weights / torch.norm(s.weights, dim=1, keepdim=True)\n",
    "weighted_distances = normalized_weights - normalized_weights[:, None, :]\n",
    "distances = torch.norm(weighted_distances, dim=2)\n",
    "intra_cluster_distances = torch.zeros(num_classes)\n",
    "for i in range(num_classes):\n",
    "    indices = (train_labels == i).nonzero().squeeze()\n",
    "    if indices.numel() == 0:\n",
    "        intra_cluster_distances[i] = float('inf')\n",
    "    else:\n",
    "        intra_cluster_distances[i] = distances[i][indices].mean()\n",
    "inter_cluster_distances = torch.zeros(num_classes, num_classes)\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        if i == j:\n",
    "            inter_cluster_distances[i][j] = float('inf')\n",
    "        else:\n",
    "            indices_i = (train_labels == i).nonzero().squeeze()\n",
    "            indices_j = (train_labels == j).nonzero().squeeze()\n",
    "            inter_cluster_distances[i][j] = (intra_cluster_distances[i] + intra_cluster_distances[j]) / distances[i][j]\n",
    "DBI = torch.max(inter_cluster_distances.sum(dim=1) / cluster_sizes)\n",
    "\n",
    "print('Davies-Bouldin Index:', DBI.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3dedc-b3d2-49f8-a74d-a11b15058d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857fd86-9ab6-45b0-b1f1-b3bdc832d823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567787c-6d62-438b-9e98-689be536c334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e2bd2-5e33-4a4d-b7d4-73c6efad91c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6dc743-516a-4782-8413-204908321549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac36ec4-387f-49b2-a944-d9399220ef2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad8fc7-d884-486d-936d-88a6166178d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
