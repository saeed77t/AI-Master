{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e3e14a-e426-4963-b4af-0bb60cb79c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from minisom import MiniSom\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dc1ae7-b32d-48f4-b438-08fc6ebe18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the root folder of your dataset\n",
    "root_folder = \"MNIST Dataset/\"\n",
    "\n",
    "# Define lists to store the image data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Loop over the folders in the root folder\n",
    "for i in range(10):\n",
    "    folder_path = root_folder + str(i) + \"/\"\n",
    "\n",
    "    # Get the label corresponding to the folder name\n",
    "    label = i\n",
    "\n",
    "    # Loop over the images in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Read the image using OpenCV and convert it to grayscale\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Add the image and label to the dataset lists\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "# Convert the data and labels lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets, with 90% of each class for training\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for i in range(10):\n",
    "    class_data = data[labels == i]\n",
    "    class_labels = labels[labels == i]\n",
    "\n",
    "    train_class_data, test_class_data, train_class_labels, test_class_labels = train_test_split(class_data, class_labels, test_size=0.1)\n",
    "\n",
    "    train_data.append(train_class_data)\n",
    "    train_labels.append(train_class_labels)\n",
    "    test_data.append(test_class_data)\n",
    "    test_labels.append(test_class_labels)\n",
    "\n",
    "# Concatenate the training and testing data and labels for each class\n",
    "train_data = np.concatenate(train_data)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "test_data = np.concatenate(test_data)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "\n",
    "# Create a pandas dataframe to store the data and labels\n",
    "train_df = pd.DataFrame(train_data.reshape(train_data.shape[0], -1))\n",
    "train_df['label'] = train_labels\n",
    "\n",
    "test_df = pd.DataFrame(test_data.reshape(test_data.shape[0], -1))\n",
    "test_df['label'] = test_labels\n",
    "\n",
    "#shuffle data frame:\n",
    "train_df = train_df.sample(frac = 1)\n",
    "test_df = test_df.sample(frac = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d0e6b6-dd42-4bbc-b907-2f6d92c78758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Train and Test  Data and labels\n",
    "TrainLabels = train_df['label']\n",
    "TrainData = train_df.drop('label',axis=1)\n",
    "TestLabels = test_df['label']\n",
    "TestData = test_df.drop('label',axis=1)\n",
    "TrainData = np.array(TrainData)\n",
    "TrainLabels = np.array(TrainLabels)\n",
    "TestLabels = np.array(TestLabels)\n",
    "TestData = np.array(TestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e31edde9-bbca-4bf3-be14-d2b293fe514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 300000 / 300000 ] 100% - 0:00:00 left \n",
      " quantization error: 5.322994255490633\n",
      "Train accuracy: 14.744444444444444  %\n",
      "Test accuracy: 14.2  %\n",
      "DBI for Winner-Takes-All approach: 2.8945307568222627\n",
      "Cluster Labels: [[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "#true Winner takes all approach with only 10 clusters \n",
    "# Load the training and test data\n",
    "training_data = TrainData\n",
    "test_data = TestData\n",
    "training_labels = TrainLabels\n",
    "test_labels = TestLabels\n",
    "\n",
    "# Flatten the training and test data and normalize it:\n",
    "training_data = training_data.reshape(training_data.shape[0], -1) / 255.\n",
    "test_data = test_data.reshape(test_data.shape[0], -1) / 255.\n",
    "\n",
    "# Define the parameters for the SOM:\n",
    "input_len = 784  # number of features\n",
    "classes = 10     # number of classes\n",
    "som_size = 10    # size of the SOM\n",
    "sigma = 1        # neighborhood radius\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Implement the winner-takes-all approach:\n",
    "# Create a SOM with one neuron for each class\n",
    "som = MiniSom(som_size, som_size, input_len, sigma=sigma, learning_rate=learning_rate, \n",
    "              neighborhood_function='gaussian', random_seed=0)\n",
    "som.pca_weights_init(training_data)\n",
    "som.train_batch(training_data, 300000, verbose=True)\n",
    "# Determine the number of images of each class that are placed in each cluster\n",
    "class_counts = np.zeros((som_size, som_size, classes))\n",
    "for index, label in np.ndenumerate(training_labels):\n",
    "    i, j = som.winner(training_data[index])\n",
    "    class_counts[i, j, label] += 1\n",
    "\n",
    "# Determine the label for each cluster\n",
    "class_labels = np.zeros((som_size, som_size))\n",
    "for i in range(som_size):\n",
    "    for j in range(som_size):\n",
    "        class_labels[i, j] = np.argmax(class_counts[i, j])\n",
    "# Determine the final class labels\n",
    "class_labels_final = np.zeros((classes,))\n",
    "for i in range(som_size):\n",
    "    for j in range(som_size):\n",
    "        class_labels_final[int(class_labels[i, j])] = np.argmax(class_counts[i, j])\n",
    "        \n",
    "# Reshape the class_labels_final array to (10,1) or (1,10)\n",
    "class_labels_final = class_labels_final.reshape((1, 10))  # or (10, 1)\n",
    "\n",
    "# Compute the train accuracy\n",
    "train_labels_pred = np.zeros(len(training_labels))\n",
    "for i in range(len(training_data)):\n",
    "    closest_neuron_dist, closest_neuron = som.winner(training_data[i])\n",
    "    train_labels_pred[i] = class_labels_final[0, closest_neuron]\n",
    "train_accuracy = accuracy_score(training_labels, train_labels_pred)\n",
    "print('Train accuracy:', train_accuracy*100 , ' %')\n",
    "\n",
    "\n",
    "# Compute the test accuracy\n",
    "test_labels_pred = np.zeros(len(test_labels))\n",
    "for i in range(len(test_data)):\n",
    "    closest_neuron_dist, closest_neuron = som.winner(test_data[i])\n",
    "    test_labels_pred[i] = class_labels_final[0, closest_neuron]\n",
    "test_accuracy = accuracy_score(test_labels, test_labels_pred)\n",
    "print('Test accuracy:', test_accuracy*100 , ' %')\n",
    "\n",
    "# Compute the Euclidean distances between each training sample and each neuron in the SOM\n",
    "weights = som.get_weights()\n",
    "distances = np.zeros((len(training_data), som_size * som_size))\n",
    "for i in range(len(training_data)):\n",
    "    for j in range(som_size * som_size):\n",
    "        distances[i, j] = np.linalg.norm(training_data[i] - weights[j // som_size, j % som_size])\n",
    "\n",
    "# Assign each training sample to the neuron it is closest to\n",
    "assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "# Compute the DBI for the SOM\n",
    "dbi_wta = davies_bouldin_score(training_data, assignments)\n",
    "print('DBI for Winner-Takes-All approach:', dbi_wta)\n",
    "\n",
    "print(\"Cluster Labels:\", class_labels_final)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c476407-7b5d-4b19-b820-65bd6bbe5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds0=[]\n",
    "ds1=[]\n",
    "ds2=[]\n",
    "ds3=[]\n",
    "ds4=[]\n",
    "ds5=[]\n",
    "ds6=[]\n",
    "ds7=[]\n",
    "ds8=[]\n",
    "ds9=[]\n",
    "lbl0=[]\n",
    "lbl1=[]\n",
    "lbl2=[]\n",
    "lbl3=[]\n",
    "lbl4=[]\n",
    "lbl5=[]\n",
    "lbl6=[]\n",
    "lbl7=[]\n",
    "lbl8=[]\n",
    "lbl9=[]\n",
    "\n",
    "poscnt = 0\n",
    "for i in range(len(training_data)):\n",
    "    if(training_labels[i]==0):\n",
    "        ds0.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl0.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl0.append(0)\n",
    "            \n",
    "    if(training_labels[i]==1):\n",
    "        ds1.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl1.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl1.append(0)\n",
    "            \n",
    "    if(training_labels[i]==2):\n",
    "        ds2.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl2.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl2.append(0)\n",
    "            \n",
    "    if(training_labels[i]==3):\n",
    "        ds3.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl3.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl3.append(0)\n",
    "\n",
    "    if(training_labels[i]==4):\n",
    "        ds4.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl4.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl4.append(0)\n",
    "            \n",
    "            \n",
    "    if(training_labels[i]==5):\n",
    "        ds5.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl5.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl5.append(0)\n",
    "            \n",
    "    if(training_labels[i]==6):\n",
    "        ds6.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl6.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl6.append(0)\n",
    "            \n",
    "    if(training_labels[i]==7):\n",
    "        ds7.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl7.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl7.append(0)\n",
    "            \n",
    "            \n",
    "    if(training_labels[i]==8):\n",
    "        ds8.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl8.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl8.append(0)\n",
    "                     \n",
    "    \n",
    "    \n",
    "    \n",
    "    if(training_labels[i]==9):\n",
    "        ds9.append(training_data[i])\n",
    "        if(train_labels_pred[i] == train_labels[i]):\n",
    "            lbl9.append(1)\n",
    "            poscnt +=1\n",
    "        else:\n",
    "            lbl9.append(0)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d8ac7-0aed-4b3b-8611-dc79a11d5e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
